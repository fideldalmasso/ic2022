{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AOwSmuikM2kG"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def intercala_listas(lista1,lista2):\n",
        "    # Assumes lista1 and lista2 are the same length \n",
        "    lista = []\n",
        "\n",
        "    for i in range(len(lista1)):\n",
        "        lista.append(lista1[i])\n",
        "        lista.append(lista2[i])\n",
        "\n",
        "    return lista"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# step 1\n",
        "\n",
        "CANT_ENTRENAMIENTO=70\n",
        "CANT_PRUEBAS=30\n",
        "TOTAL = CANT_ENTRENAMIENTO+CANT_PRUEBAS\n",
        "USAR_MASK = False\n",
        "mask = \"\"\n",
        "if USAR_MASK:\n",
        "    mask = \"_with_mask\"\n",
        "\n",
        "filenames = []\n",
        "labels = []\n",
        "\n",
        "for i in range(1,TOTAL+1):\n",
        "    for type in ['COVID','Normal']:\n",
        "        filenames.append(f'./dataset/{type}/images{mask}/{type}-{i}.png')\n",
        "        labels.append(1 if type == 'COVID' else 0)\n",
        "\n",
        "filenames_train = filenames[0:CANT_ENTRENAMIENTO*2]\n",
        "labels_train = labels[0:CANT_ENTRENAMIENTO*2]\n",
        "\n",
        "filenames_test = filenames[CANT_ENTRENAMIENTO*2:TOTAL*2]\n",
        "labels_test = labels[CANT_ENTRENAMIENTO*2:TOTAL*2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# step 2: create a dataset returning slices of `filenames`\n",
        "datos_train = tf.data.Dataset.from_tensor_slices((filenames_train, labels_train))\n",
        "datos_test = tf.data.Dataset.from_tensor_slices((filenames_test, labels_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KuQPdKw9TIdP"
      },
      "outputs": [],
      "source": [
        "#Obtenemos en variables separadas los datos de entrenamiento (60k) y pruebas (10k)\n",
        "datos_entrenamiento, datos_pruebas = datos_train, datos_test\n",
        "datos_entrenamiento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wxBaYWyHTX4_"
      },
      "outputs": [],
      "source": [
        "nombres_clases = ['normal','covid']\n",
        "nombres_clases\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fI7XnPjHTiYR"
      },
      "outputs": [],
      "source": [
        "#Funcion de normalizacion para los datos (Pasar de 0-255 a 0-1)\n",
        "#Hace que la red aprenda mejor y mas rapido\n",
        "\n",
        "def _parse_function(filename, label):\n",
        "  image_string = tf.io.read_file(filename)\n",
        "  image_decoded = tf.image.decode_image(image_string, channels=0)\n",
        "  image = tf.cast(image_decoded, tf.float32)\n",
        "  image /= 255 \n",
        "  return image, label\n",
        "\n",
        "#Normalizar los datos de entrenamiento y pruebas con la funcion que hicimos\n",
        "datos_entrenamiento = datos_entrenamiento.map(_parse_function)\n",
        "datos_pruebas = datos_pruebas.map(_parse_function)\n",
        "\n",
        "#Agregar a cache (usar memoria en lugar de disco, entrenamiento mas rapido)\n",
        "datos_entrenamiento = datos_entrenamiento.cache()\n",
        "datos_pruebas = datos_pruebas.cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "ZmTRardXT_KU",
        "outputId": "69f175ff-0309-4765-f832-81d2b33cf53f"
      },
      "outputs": [],
      "source": [
        "#Mostrar una imagen de los datos de pruebas, de momento mostremos la primera\n",
        "for imagen, etiqueta in datos_entrenamiento.take(1):\n",
        "  break\n",
        "imagen = imagen.numpy().reshape((299,299)) #Redimensionar, cosas de tensores, lo veremos despues# imagen = imagen.numpy().reshape((28,28)) #Redimensionar, cosas de tensores, lo veremos despues\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#Dibujar dibujar\n",
        "plt.figure()\n",
        "plt.imshow(imagen, cmap=plt.cm.binary)\n",
        "plt.colorbar()\n",
        "plt.grid(False)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 589
        },
        "id": "AC31ZBTnUdft",
        "outputId": "4eaea1b1-e366-4675-8ee9-5ce0bc960829"
      },
      "outputs": [],
      "source": [
        "#Dibujar mas\n",
        "plt.figure(figsize=(10,10))\n",
        "# for i, (imagen, etiqueta) in enumerate(datos_entrenamiento.take(25)):\n",
        "for i, (imagen, etiqueta) in enumerate(datos_entrenamiento.take(25)):\n",
        "  imagen = imagen.numpy().reshape((299,299))\n",
        "  plt.subplot(5,5,i+1)\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "  plt.grid(False)\n",
        "  plt.imshow(imagen, cmap=plt.cm.binary)\n",
        "  plt.xlabel(nombres_clases[etiqueta])\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Qgu40h_UyYZ"
      },
      "outputs": [],
      "source": [
        "#Crear el modelo\n",
        "modelo = tf.keras.Sequential([\n",
        "  tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(299, 299, 1)),\n",
        "  tf.keras.layers.MaxPooling2D(2, 2),\n",
        "  tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
        "  tf.keras.layers.MaxPooling2D(2,2),\n",
        "  tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "  tf.keras.layers.MaxPooling2D(2,2),\n",
        "  tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "  tf.keras.layers.MaxPooling2D(2,2),\n",
        "  tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
        "  tf.keras.layers.MaxPooling2D(2,2),\n",
        "  tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
        "  tf.keras.layers.MaxPooling2D(2,2),\n",
        "  tf.keras.layers.Flatten(), #1 - blanco y negro\n",
        "  tf.keras.layers.Dropout(0.5),\n",
        "  tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
        "  tf.keras.layers.Dense(2, activation=tf.nn.softmax),\n",
        "  #tf.keras.layers.Dense(10, activation=tf.nn.sigmoid) #Para redes de clasificacion\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# modelo = tf.keras.models.Sequential([\n",
        "#     tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(299, 299, 1)),\n",
        "#     tf.keras.layers.MaxPooling2D(2, 2),\n",
        "#     tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
        "#     tf.keras.layers.MaxPooling2D(2,2),\n",
        "#     tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "#     tf.keras.layers.MaxPooling2D(2,2),\n",
        "#     tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "#     tf.keras.layers.MaxPooling2D(2,2),\n",
        "#     tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
        "#     tf.keras.layers.MaxPooling2D(2,2),\n",
        "#     tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
        "#     tf.keras.layers.MaxPooling2D(2,2),\n",
        "#     tf.keras.layers.Flatten(),\n",
        "#     tf.keras.layers.Dropout(0.5),\n",
        "#     tf.keras.layers.Dense(128, activation='relu'),\n",
        "#     tf.keras.layers.Dense(512, activation=\"sigmoid\")\n",
        "# ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tkRSnyokVOna"
      },
      "outputs": [],
      "source": [
        "#Compilar el modelo\n",
        "modelo.compile(\n",
        "    optimizer='adam',\n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "    metrics=['accuracy']\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j1gk7K6yVlvY"
      },
      "outputs": [],
      "source": [
        "# #Los numeros de datos en entrenamiento y pruebas (60k y 10k)\n",
        "num_ej_entrenamiento = CANT_ENTRENAMIENTO\n",
        "num_ej_pruebas = CANT_PRUEBAS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C_MQTDkoVsFH",
        "outputId": "8cd0deb6-363d-4f6e-97da-87ce55ab4794"
      },
      "outputs": [],
      "source": [
        "print(num_ej_entrenamiento)\n",
        "print(num_ej_pruebas)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "teT6nUy_Vddy"
      },
      "outputs": [],
      "source": [
        "#El trabajo por lotes permite que entrenamientos con gran cantidad de datos se haga de manera mas eficiente\n",
        "TAMANO_LOTE = 32\n",
        "\n",
        "#Shuffle y repeat hacen que los datos esten mezclados de manera aleatoria para que la red\n",
        "#no se vaya a aprender el orden de las cosas\n",
        "datos_entrenamiento = datos_entrenamiento.repeat().shuffle(num_ej_entrenamiento).batch(TAMANO_LOTE)\n",
        "datos_pruebas = datos_pruebas.batch(TAMANO_LOTE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1E0QFpqyV3u6"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "#Entrenar\n",
        "historial = modelo.fit(datos_entrenamiento, epochs=60,batch_size=TAMANO_LOTE, steps_per_epoch=math.ceil(num_ej_entrenamiento/TAMANO_LOTE))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "53-FsRxzWQhQ",
        "outputId": "79558c5f-8e23-4cd5-fe19-8bbc31c78f05"
      },
      "outputs": [],
      "source": [
        "#Ver la funcion de perdida\n",
        "plt.xlabel(\"# Epoca\")\n",
        "plt.ylabel(\"Magnitud de p√©rdida\")\n",
        "plt.plot(historial.history[\"loss\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 589
        },
        "id": "V4q7-hKbWb4V",
        "outputId": "e47ccd4f-1fae-45f3-ac87-7430058de540"
      },
      "outputs": [],
      "source": [
        "#Pintar una cuadricula con varias predicciones, y marcar si fue correcta (azul) o incorrecta (roja)\n",
        "import numpy as np\n",
        "\n",
        "for imagenes_prueba, etiquetas_prueba in datos_pruebas.take(1):\n",
        "  imagenes_prueba = imagenes_prueba.numpy()\n",
        "  etiquetas_prueba = etiquetas_prueba.numpy()\n",
        "  predicciones = modelo.predict(imagenes_prueba)\n",
        "  \n",
        "def graficar_imagen(i, arr_predicciones, etiquetas_reales, imagenes):\n",
        "  arr_predicciones, etiqueta_real, img = arr_predicciones[i], etiquetas_reales[i], imagenes[i]\n",
        "  plt.grid(False)\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "  \n",
        "  plt.imshow(img[...,0], cmap=plt.cm.binary)\n",
        "\n",
        "  etiqueta_prediccion = np.argmax(arr_predicciones)\n",
        "  if etiqueta_prediccion == etiqueta_real:\n",
        "    color = 'blue'\n",
        "  else:\n",
        "    color = 'red'\n",
        "  \n",
        "  plt.xlabel(\"{} {:2.0f}% ({})\".format(nombres_clases[etiqueta_prediccion],\n",
        "                                100*np.max(arr_predicciones),\n",
        "                                nombres_clases[etiqueta_real]),\n",
        "                                color=color)\n",
        "  \n",
        "def graficar_valor_arreglo(i, arr_predicciones, etiqueta_real):\n",
        "  arr_predicciones, etiqueta_real = arr_predicciones[i], etiqueta_real[i]\n",
        "  plt.grid(False)\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "  grafica = plt.bar(range(2), arr_predicciones, color=\"#777777\")\n",
        "  plt.ylim([0, 1]) \n",
        "  etiqueta_prediccion = np.argmax(arr_predicciones)\n",
        "  \n",
        "  grafica[etiqueta_prediccion].set_color('red')\n",
        "  grafica[etiqueta_real].set_color('blue')\n",
        "  \n",
        "filas = 5\n",
        "columnas = 5\n",
        "num_imagenes = filas*columnas\n",
        "plt.figure(figsize=(2*2*columnas, 2*filas))\n",
        "for i in range(num_imagenes):\n",
        "  plt.subplot(filas, 2*columnas, 2*i+1)\n",
        "  graficar_imagen(i, predicciones, etiquetas_prueba, imagenes_prueba)\n",
        "  plt.subplot(filas, 2*columnas, 2*i+2)\n",
        "  graficar_valor_arreglo(i, predicciones, etiquetas_prueba)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "48ZC4GNiYSAH",
        "outputId": "b1225439-709f-43e9-f29e-4beb120d0a60"
      },
      "outputs": [],
      "source": [
        "#Probar una imagen suelta\n",
        "imagen = imagenes_prueba[4] #AL ser la variable imagenes_prueba solo tiene lo que se le puso en el bloque anterior heheh\n",
        "imagen = np.array([imagen])\n",
        "prediccion = modelo.predict(imagen)\n",
        "\n",
        "print(\"Prediccion: \" + nombres_clases[np.argmax(prediccion[0])])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.8.13 ('tf_m1')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "463463f1237fb8026c58b097e71df3687e233fc79d832dbedb3d892e90e258e4"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
