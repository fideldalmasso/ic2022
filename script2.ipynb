{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "AOwSmuikM2kG"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "def intercala_listas(lista1,lista2):\n",
        "    # Assumes lista1 and lista2 are the same length \n",
        "    lista = []\n",
        "\n",
        "    for i in range(len(lista1)):\n",
        "        lista.append(lista1[i])\n",
        "        lista.append(lista2[i])\n",
        "\n",
        "    return lista"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "# step 1\n",
        "\n",
        "CANT_ENTRENAMIENTO=70\n",
        "CANT_PRUEBAS=30\n",
        "TOTAL = CANT_ENTRENAMIENTO+CANT_PRUEBAS\n",
        "USAR_MASK = False\n",
        "mask = \"\"\n",
        "if USAR_MASK:\n",
        "    mask = \"_with_mask\"\n",
        "\n",
        "filenames = []\n",
        "labels = []\n",
        "\n",
        "for i in range(1,TOTAL+1):\n",
        "    for type in ['COVID','Normal']:\n",
        "        filenames.append(f'./dataset/{type}/images{mask}/{type}-{i}.png')\n",
        "        labels.append(1 if type == 'COVID' else 0)\n",
        "\n",
        "filenames_train = filenames[0:CANT_ENTRENAMIENTO*2]\n",
        "labels_train = labels[0:CANT_ENTRENAMIENTO*2]\n",
        "\n",
        "filenames_test = filenames[CANT_ENTRENAMIENTO*2:TOTAL*2]\n",
        "labels_test = labels[CANT_ENTRENAMIENTO*2:TOTAL*2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-09-20 16:18:21.097387: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/fidel/gurobi952/linux64/lib\n",
            "2022-09-20 16:18:21.097417: W tensorflow/stream_executor/cuda/cuda_driver.cc:263] failed call to cuInit: UNKNOWN ERROR (303)\n",
            "2022-09-20 16:18:21.097437: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (pop-os2): /proc/driver/nvidia/version does not exist\n",
            "2022-09-20 16:18:21.097726: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
          ]
        }
      ],
      "source": [
        "# step 2: create a dataset returning slices of `filenames`\n",
        "datos_train = tf.data.Dataset.from_tensor_slices((filenames_train, labels_train))\n",
        "datos_test = tf.data.Dataset.from_tensor_slices((filenames_test, labels_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "KuQPdKw9TIdP"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<TensorSliceDataset element_spec=(TensorSpec(shape=(), dtype=tf.string, name=None), TensorSpec(shape=(), dtype=tf.int32, name=None))>"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Obtenemos en variables separadas los datos de entrenamiento (60k) y pruebas (10k)\n",
        "datos_entrenamiento, datos_pruebas = datos_train, datos_test\n",
        "datos_entrenamiento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "wxBaYWyHTX4_"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['normal', 'covid']"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nombres_clases = ['normal','covid']\n",
        "nombres_clases\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "fI7XnPjHTiYR"
      },
      "outputs": [],
      "source": [
        "#Funcion de normalizacion para los datos (Pasar de 0-255 a 0-1)\n",
        "#Hace que la red aprenda mejor y mas rapido\n",
        "\n",
        "def _parse_function(filename, label):\n",
        "  image_string = tf.io.read_file(filename)\n",
        "  image_decoded = tf.image.decode_image(image_string, channels=0)\n",
        "  image = tf.cast(image_decoded, tf.float32)\n",
        "  image /= 255 \n",
        "  return image, label\n",
        "\n",
        "#Normalizar los datos de entrenamiento y pruebas con la funcion que hicimos\n",
        "datos_entrenamiento = datos_entrenamiento.map(_parse_function)\n",
        "datos_pruebas = datos_pruebas.map(_parse_function)\n",
        "\n",
        "#Agregar a cache (usar memoria en lugar de disco, entrenamiento mas rapido)\n",
        "datos_entrenamiento = datos_entrenamiento.cache()\n",
        "datos_pruebas = datos_pruebas.cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "ZmTRardXT_KU",
        "outputId": "69f175ff-0309-4765-f832-81d2b33cf53f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-09-20 16:18:21.692699: W tensorflow/core/kernels/data/cache_dataset_ops.cc:856] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "cannot reshape array of size 268203 into shape (299,299)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[0;32mIn [13], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m imagen, etiqueta \u001b[38;5;129;01min\u001b[39;00m datos_entrenamiento\u001b[38;5;241m.\u001b[39mtake(\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m      3\u001b[0m   \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m imagen \u001b[38;5;241m=\u001b[39m \u001b[43mimagen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m299\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m299\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m#Redimensionar, cosas de tensores, lo veremos despues# imagen = imagen.numpy().reshape((28,28)) #Redimensionar, cosas de tensores, lo veremos despues\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m#Dibujar dibujar\u001b[39;00m\n",
            "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 268203 into shape (299,299)"
          ]
        }
      ],
      "source": [
        "#Mostrar una imagen de los datos de pruebas, de momento mostremos la primera\n",
        "for imagen, etiqueta in datos_entrenamiento.take(1):\n",
        "  break\n",
        "imagen = imagen.numpy().reshape((299,299)) #Redimensionar, cosas de tensores, lo veremos despues# imagen = imagen.numpy().reshape((28,28)) #Redimensionar, cosas de tensores, lo veremos despues\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#Dibujar dibujar\n",
        "plt.figure()\n",
        "plt.imshow(imagen, cmap=plt.cm.binary)\n",
        "plt.colorbar()\n",
        "plt.grid(False)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 589
        },
        "id": "AC31ZBTnUdft",
        "outputId": "4eaea1b1-e366-4675-8ee9-5ce0bc960829"
      },
      "outputs": [],
      "source": [
        "#Dibujar mas\n",
        "plt.figure(figsize=(10,10))\n",
        "# for i, (imagen, etiqueta) in enumerate(datos_entrenamiento.take(25)):\n",
        "for i, (imagen, etiqueta) in enumerate(datos_entrenamiento.take(25)):\n",
        "  imagen = imagen.numpy().reshape((299,299))\n",
        "  plt.subplot(5,5,i+1)\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "  plt.grid(False)\n",
        "  plt.imshow(imagen, cmap=plt.cm.binary)\n",
        "  plt.xlabel(nombres_clases[etiqueta])\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Qgu40h_UyYZ"
      },
      "outputs": [],
      "source": [
        "#Crear el modelo\n",
        "modelo = tf.keras.Sequential([\n",
        "  tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(299, 299, 1)),\n",
        "  tf.keras.layers.MaxPooling2D(2, 2),\n",
        "  tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
        "  tf.keras.layers.MaxPooling2D(2,2),\n",
        "  tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "  tf.keras.layers.MaxPooling2D(2,2),\n",
        "  tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "  tf.keras.layers.MaxPooling2D(2,2),\n",
        "  tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
        "  tf.keras.layers.MaxPooling2D(2,2),\n",
        "  tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
        "  tf.keras.layers.MaxPooling2D(2,2),\n",
        "  tf.keras.layers.Flatten(), #1 - blanco y negro\n",
        "  tf.keras.layers.Dropout(0.5),\n",
        "  tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
        "  tf.keras.layers.Dense(2, activation=tf.nn.softmax),\n",
        "  #tf.keras.layers.Dense(10, activation=tf.nn.sigmoid) #Para redes de clasificacion\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# modelo = tf.keras.models.Sequential([\n",
        "#     tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(299, 299, 1)),\n",
        "#     tf.keras.layers.MaxPooling2D(2, 2),\n",
        "#     tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
        "#     tf.keras.layers.MaxPooling2D(2,2),\n",
        "#     tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "#     tf.keras.layers.MaxPooling2D(2,2),\n",
        "#     tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "#     tf.keras.layers.MaxPooling2D(2,2),\n",
        "#     tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
        "#     tf.keras.layers.MaxPooling2D(2,2),\n",
        "#     tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
        "#     tf.keras.layers.MaxPooling2D(2,2),\n",
        "#     tf.keras.layers.Flatten(),\n",
        "#     tf.keras.layers.Dropout(0.5),\n",
        "#     tf.keras.layers.Dense(128, activation='relu'),\n",
        "#     tf.keras.layers.Dense(512, activation=\"sigmoid\")\n",
        "# ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tkRSnyokVOna"
      },
      "outputs": [],
      "source": [
        "#Compilar el modelo\n",
        "modelo.compile(\n",
        "    optimizer='adam',\n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "    metrics=['accuracy']\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j1gk7K6yVlvY"
      },
      "outputs": [],
      "source": [
        "# #Los numeros de datos en entrenamiento y pruebas (60k y 10k)\n",
        "num_ej_entrenamiento = CANT_ENTRENAMIENTO\n",
        "num_ej_pruebas = CANT_PRUEBAS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C_MQTDkoVsFH",
        "outputId": "8cd0deb6-363d-4f6e-97da-87ce55ab4794"
      },
      "outputs": [],
      "source": [
        "print(num_ej_entrenamiento)\n",
        "print(num_ej_pruebas)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "teT6nUy_Vddy"
      },
      "outputs": [],
      "source": [
        "#El trabajo por lotes permite que entrenamientos con gran cantidad de datos se haga de manera mas eficiente\n",
        "TAMANO_LOTE = 32\n",
        "\n",
        "#Shuffle y repeat hacen que los datos esten mezclados de manera aleatoria para que la red\n",
        "#no se vaya a aprender el orden de las cosas\n",
        "datos_entrenamiento = datos_entrenamiento.repeat().shuffle(num_ej_entrenamiento).batch(TAMANO_LOTE)\n",
        "datos_pruebas = datos_pruebas.batch(TAMANO_LOTE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1E0QFpqyV3u6"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "#Entrenar\n",
        "historial = modelo.fit(datos_entrenamiento, epochs=60,batch_size=TAMANO_LOTE, steps_per_epoch=math.ceil(num_ej_entrenamiento/TAMANO_LOTE))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "53-FsRxzWQhQ",
        "outputId": "79558c5f-8e23-4cd5-fe19-8bbc31c78f05"
      },
      "outputs": [],
      "source": [
        "#Ver la funcion de perdida\n",
        "plt.xlabel(\"# Epoca\")\n",
        "plt.ylabel(\"Magnitud de pérdida\")\n",
        "plt.plot(historial.history[\"loss\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 589
        },
        "id": "V4q7-hKbWb4V",
        "outputId": "e47ccd4f-1fae-45f3-ac87-7430058de540"
      },
      "outputs": [],
      "source": [
        "#Pintar una cuadricula con varias predicciones, y marcar si fue correcta (azul) o incorrecta (roja)\n",
        "import numpy as np\n",
        "\n",
        "for imagenes_prueba, etiquetas_prueba in datos_pruebas.take(1):\n",
        "  imagenes_prueba = imagenes_prueba.numpy()\n",
        "  etiquetas_prueba = etiquetas_prueba.numpy()\n",
        "  predicciones = modelo.predict(imagenes_prueba)\n",
        "  \n",
        "def graficar_imagen(i, arr_predicciones, etiquetas_reales, imagenes):\n",
        "  arr_predicciones, etiqueta_real, img = arr_predicciones[i], etiquetas_reales[i], imagenes[i]\n",
        "  plt.grid(False)\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "  \n",
        "  plt.imshow(img[...,0], cmap=plt.cm.binary)\n",
        "\n",
        "  etiqueta_prediccion = np.argmax(arr_predicciones)\n",
        "  if etiqueta_prediccion == etiqueta_real:\n",
        "    color = 'blue'\n",
        "  else:\n",
        "    color = 'red'\n",
        "  \n",
        "  plt.xlabel(\"{} {:2.0f}% ({})\".format(nombres_clases[etiqueta_prediccion],\n",
        "                                100*np.max(arr_predicciones),\n",
        "                                nombres_clases[etiqueta_real]),\n",
        "                                color=color)\n",
        "  \n",
        "def graficar_valor_arreglo(i, arr_predicciones, etiqueta_real):\n",
        "  arr_predicciones, etiqueta_real = arr_predicciones[i], etiqueta_real[i]\n",
        "  plt.grid(False)\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "  grafica = plt.bar(range(2), arr_predicciones, color=\"#777777\")\n",
        "  plt.ylim([0, 1]) \n",
        "  etiqueta_prediccion = np.argmax(arr_predicciones)\n",
        "  \n",
        "  grafica[etiqueta_prediccion].set_color('red')\n",
        "  grafica[etiqueta_real].set_color('blue')\n",
        "  \n",
        "filas = 5\n",
        "columnas = 5\n",
        "num_imagenes = filas*columnas\n",
        "plt.figure(figsize=(2*2*columnas, 2*filas))\n",
        "for i in range(num_imagenes):\n",
        "  plt.subplot(filas, 2*columnas, 2*i+1)\n",
        "  graficar_imagen(i, predicciones, etiquetas_prueba, imagenes_prueba)\n",
        "  plt.subplot(filas, 2*columnas, 2*i+2)\n",
        "  graficar_valor_arreglo(i, predicciones, etiquetas_prueba)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "48ZC4GNiYSAH",
        "outputId": "b1225439-709f-43e9-f29e-4beb120d0a60"
      },
      "outputs": [],
      "source": [
        "#Probar una imagen suelta\n",
        "imagen = imagenes_prueba[4] #AL ser la variable imagenes_prueba solo tiene lo que se le puso en el bloque anterior heheh\n",
        "imagen = np.array([imagen])\n",
        "prediccion = modelo.predict(imagen)\n",
        "\n",
        "print(\"Prediccion: \" + nombres_clases[np.argmax(prediccion[0])])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UxgBjoTLZK3d"
      },
      "outputs": [],
      "source": [
        "#Exportacion del modelo a h5\n",
        "#modelo.save('modelo_exportado.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P1ayq2beZRFB"
      },
      "outputs": [],
      "source": [
        "#Instalar tensorflowjs para convertir el h5 a un modelo que pueda cargar tensorflowjs en un explorador\n",
        "# %pip install tensorflowjs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V3hMCzRDZYAX",
        "outputId": "8b402108-996b-4091-f317-a86fc8c7ea37"
      },
      "outputs": [],
      "source": [
        "#Convertir el archivo h5 a formato de tensorflowjs\n",
        "#!mkdir tfjs_target_dir\n",
        "#!tensorflowjs_converter --input_format keras modelo_exportado.h5 tfjs_target_dir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0T_QNwOzZhWU",
        "outputId": "3d6ef164-0cd0-46b9-b885-b1d93556ba8f"
      },
      "outputs": [],
      "source": [
        "#Veamos si si creo la carpeta\n",
        "#!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PNlUEbRpZkgT",
        "outputId": "c2bf286e-e759-4b5b-c5d0-4aeda84e3265"
      },
      "outputs": [],
      "source": [
        "#Veamos el contenido de la carpeta\n",
        "#!ls tfjs_target_dir"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.4 ('ic')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    },
    "vscode": {
      "interpreter": {
        "hash": "de8996398a2c635a89e441c04fb2848728bd0c76f3d1c1d8d9675eb4f548f0fd"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
